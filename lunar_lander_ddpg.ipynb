{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ikr2p0Js8iB4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddpg import DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def live_plot(data_dict, figsize=(15,5)):\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    for label, data in data_dict.items():\n",
    "        plt.plot(data, label=label)\n",
    "    \n",
    "    plt.legend(loc='lower left')\n",
    "    plt.show();\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xn96qw7tsbhl"
   },
   "outputs": [],
   "source": [
    "def mkdir(base, name):\n",
    "\n",
    "    path = os.path.join(base, name)\n",
    "  \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "  \n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'LunarLanderContinuous-v2'\n",
    "save_models = True\n",
    "seed = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snfGHM_8rAnv"
   },
   "source": [
    "##### Initialize environment and set seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-xn7OWBrPP8",
    "outputId": "ac94c862-ca63-4ff6-c338-f4f65a4c91b2"
   },
   "outputs": [],
   "source": [
    "env = gym.make(env_name)\n",
    "\n",
    "env.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = float(env.action_space.high[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zg1ISVQGqObn"
   },
   "source": [
    "##### Create folder in which trained models will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOSuBYdsqVMX"
   },
   "outputs": [],
   "source": [
    "if all([save_models, not os.path.exists('./pytorch_models')]):\n",
    "    os.makedirs('./pytorch_models')\n",
    "if all([save_models, not os.path.exists('./pytorch_models/all_ddpg')]):\n",
    "    os.makedirs('./pytorch_models/all_ddpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAs1OaNYp5ht",
    "outputId": "d22ab539-f287-4856-c7a9-f627db21d77d"
   },
   "outputs": [],
   "source": [
    "file_name = f'DDPG_{env_name}_{seed}'\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize agent parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 1e5\n",
    "batch_size = 100\n",
    "\n",
    "gamma = 0.99\n",
    "tau = 5e-3\n",
    "policy_freq = 2\n",
    "lr = 1e-3\n",
    "\n",
    "policy_noise = 0.2\n",
    "noise_clip = 0.5\n",
    "expl_noise = 1.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zaaTcOGKsLyh",
    "outputId": "53a75b83-e251-496b-c21e-64c7d45fd8f0"
   },
   "outputs": [],
   "source": [
    "agent = DDPG(\n",
    "    state_dim, \n",
    "    action_dim, \n",
    "    max_action,\n",
    "    eta=lr,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vmr4mQWGtwYA"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXNQHlxItDHz"
   },
   "source": [
    "##### Initialize training variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent.load(file_name, './pytorch_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_step = 2e4 # Number of random steps at start\n",
    "max_steps = 1000 # Max steps per episode\n",
    "\n",
    "episodes = 1500\n",
    "total_steps = 0\n",
    "training = False\n",
    "report = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_trace = collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot noise decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_decay(eta, step, decay=3e-5):\n",
    "    #return eta\n",
    "    return eta * 1/(decay*step + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = []\n",
    "eta = expl_noise\n",
    "\n",
    "for i in np.arange(episodes):\n",
    "    eta = noise_decay(eta, i)\n",
    "\n",
    "    trace.append(eta)\n",
    "\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(trace)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in np.arange(1, episodes):             \n",
    "    \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    episode_reward = []\n",
    "    steps = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    while not done:        \n",
    "        \n",
    "        if total_steps == starting_step:\n",
    "            print('Begin training')\n",
    "            training = True\n",
    "            \n",
    "        if not training:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = agent.select_action(np.array(obs))\n",
    "            \n",
    "            if expl_noise != 0:\n",
    "                noise = np.random.normal(0, expl_noise, size=env.action_space.shape[0])\n",
    "                action = (action+noise).clip(env.action_space.low, env.action_space.high)\n",
    "                \n",
    "        new_obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        done = (done) or (steps >= max_steps)\n",
    "        #reward *= 2 if steps >= max_steps else 1 ###\n",
    "\n",
    "        episode_reward.append(reward)\n",
    "        agent.replay_buffer.add((obs, new_obs, action, reward, int(done)))\n",
    "        \n",
    "        obs = new_obs\n",
    "        steps += 1\n",
    "        total_steps += 1\n",
    "\n",
    "\n",
    "    if training:\n",
    "        expl_noise = noise_decay(expl_noise, episode) ###\n",
    "        #expl_noise = noise_decay(expl_noise, total_steps, decay=1e-9) ###\n",
    "    \n",
    "    agent.train(steps, batch_size, gamma, policy_noise, noise_clip)\n",
    "    reward_trace['episode_reward'].append(sum(episode_reward))\n",
    "    reward_trace['exploration_noise'].append(round(expl_noise, 9))\n",
    "    live_plot(reward_trace)\n",
    " \n",
    "    if episode % report == 0:\n",
    "        \n",
    "        print('Episode:', episode)\n",
    "        print('Average score:', np.mean(reward_trace['episode_reward'][-report:]))\n",
    "        print('Exploration noise:', reward_trace['exploration_noise'][-1])\n",
    "        print('Training:', training)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        agent.save(\n",
    "            f'{file_name}_{episode}', \n",
    "            './pytorch_models/all_ddpg',\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot reward trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(reward_trace['episode_reward'], 'b')\n",
    "#plt.plot(reward_trace['episode_reward'][:10], 'r')\n",
    "\n",
    "plt.axvline(1200, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save only model from selected point in training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1200\n",
    "\n",
    "agent.load(\n",
    "    f'{file_name}_{idx}', \n",
    "    './pytorch_models/all_ddpg',\n",
    ")\n",
    "\n",
    "agent.save(\n",
    "    file_name, \n",
    "    './pytorch_models',\n",
    ")\n",
    "\n",
    "for item in os.listdir('./pytorch_models/all_ddpg'):\n",
    "    os.remove(os.path.join('./pytorch_models/all_ddpg', item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Y2nGdtlKVydr",
    "Jb7TTaHxWbQD",
    "HRDDce8FXef7",
    "NzIDuONodenW",
    "ka-ZRtQvjBex",
    "gGuKmH_ijf7U",
    "Hjwf2HCol3XP",
    "kop-C96Aml8O",
    "qEAzOd47mv1Z",
    "5YdPG4HXnNsh",
    "HWEgDAQxnbem",
    "ZI60VN2Unklh",
    "xm-4b3p6rglE",
    "31n5eb03p-Fm",
    "q9gsjvtPqLgT",
    "wi6e2-_pu05e"
   ],
   "name": "TD3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
